{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC7cimW6Rnxs",
        "colab_type": "code",
        "outputId": "f2768c4f-e212-4f03-b885-fa48d2974f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## CELL 1 to execute ##\n",
        "# install nltk\n",
        "# install pandas\n",
        "# install numpy\n",
        "# import nltk\n",
        "#import glob\n",
        "# install num2words\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd0-SMJiUPh4",
        "colab_type": "code",
        "outputId": "85e67aa8-aba9-475c-f732-a5e148abfe46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "## CELL 2 to execute ##\n",
        "pip install num2words"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.6/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qN5VBj_USij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 3 to execute ##\n",
        "#import all necessities \n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize \n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from num2words import num2words\n",
        "from nltk.corpus import stopwords \n",
        "import pickle\n",
        "import math\n",
        "import operator\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "ps = PorterStemmer() \n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sge8RQhrMOVl",
        "colab_type": "code",
        "outputId": "263acd1e-7892-4ff2-a293-b09bd02d89bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## CELL 4 to execute ##\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3fNG_UTUwJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### CELL Inverted List ###\n",
        "### PLEASE NOTE THAT Inv_list is \"PICKLED\" (myInverted_List_IR4.pickle) in order to save time of creating inverted list again and again ###\n",
        "###Please avoid executing this code.Inverted list is alreadu PICKLED ####\n",
        "#### Inverted List (Inv_list) with tf values ####\n",
        "#### Final inverted list (INV) with TF-IDF value is created in later lines of code ###\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "Inv_list = {} \n",
        "cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "for group in cat_list:\n",
        "  for filename in glob.glob(\"drive/My Drive/IR4/\"+group+\"/*\"):\n",
        "    \n",
        "    length=len(filename)\n",
        "    j=0\n",
        "    for k in range(length-1,-1,-1):\n",
        "      if filename[k]=='/':\n",
        "        j=k\n",
        "        break\n",
        "    print(filename[j+1:len(filename)])\n",
        "    if not os.path.isdir(filename):\n",
        "      text = open(filename,\"r+\",errors='ignore') \n",
        "      var=(text.read())\n",
        "      var=var.replace(',','')\n",
        "      words_tokens=tokenizer.tokenize(var)\n",
        "      words = [w for w in words_tokens if not w in stop_words] \n",
        " \n",
        "\n",
        "      \n",
        "      Words=[]\n",
        "      for w in words:\n",
        "        if w.isdigit():\n",
        "  \n",
        "          Words.append(ps.stem(num2words(w)))\n",
        "        else:\n",
        "          Words.append(ps.stem(w))\n",
        "\n",
        "      for word in Words:\n",
        "        \n",
        "        if word not in Inv_list.keys():\n",
        "          List=[tuple([filename[j+1:len(filename)],1])]\n",
        "          Inv_list.update({word:List})\n",
        "        else:\n",
        "          val=Inv_list.get(word)\n",
        "          flag=0\n",
        "          i=0\n",
        "          c=0\n",
        "          for v in val:\n",
        "            if v[0] ==filename[j+1:len(filename)]:\n",
        "\n",
        "              flag=1\n",
        "              c=i\n",
        "              break\n",
        "            i=i+1\n",
        "\n",
        "          if flag==0:\n",
        "            val.append(tuple([filename[j+1:len(filename)],1]))\n",
        "          if flag==1:\n",
        "            temp=val[c]\n",
        "            val.pop(c)\n",
        "            t=tuple([temp[0],temp[1]+1])\n",
        "            val.append(t)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoET8vjvTVvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Code to Create Pickle file for Inverted List ###\n",
        "pickle_out = open(\"drive/My Drive/myInverted_List_IR4.pickle\",\"wb\")\n",
        "pickle.dump(Inv_list, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NnDeo2iTaPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 5 to execute ##\n",
        "### Code to extract inverted List from Pickled file ###\n",
        "\n",
        "pickle_in = open(\"drive/My Drive/myInverted_List_IR4.pickle\",\"rb\")\n",
        "Inv_list= pickle.load(pickle_in)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlHRSuxVb8s9",
        "colab_type": "code",
        "outputId": "299a9465-4c82-40cb-a0eb-453fdb2e6730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## CELL 6 to execute ##\n",
        "### Code to calculate total number of documents in the corpus ### \n",
        "\n",
        "Num=0\n",
        "cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "for group in cat_list:\n",
        "  for filename in glob.glob(\"drive/My Drive/IR4/\"+group+\"/*\"):\n",
        "    Num=Num+1\n",
        "print(Num)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1btY-uLaTlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 7 to execute ##\n",
        "### Final inverted list (Inv) with TF-IDF values ###\n",
        "\n",
        "Inv={}\n",
        "Inv_final={}\n",
        "for key in Inv_list.keys():\n",
        "  df=len(Inv_list.get(key))\n",
        "  df=math.log((Num/df),10)\n",
        "  val=Inv_list.get(key)\n",
        "  List=[]\n",
        "  for item in val:\n",
        "    tf_idf=(1+math.log(item[1],10))*df\n",
        "    List.append(tuple([item[0],tf_idf]))\n",
        "  Inv_final.update({key:List})\n",
        "Inv_list=Inv_final \n",
        "\n",
        "def last(n):\n",
        "  return n[1]   \n",
        "\n",
        "for key in Inv_list.keys():\n",
        "  temp=Inv_list.get(key)\n",
        "  temp=sorted(temp, key = last,reverse=True)\n",
        "  Inv.update({key:temp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR61c502dt64",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## Code to create document vectors (Docs_vec) for all 5k documents in the corpus ###\n",
        "## PLEASE NOTE THAT Docs_vec is PICKLED (Docs_Vec_IR4.pickle) in order to save time of creating Document vectors again and again ###\n",
        "### Avoid executing this code.Use PICKELD File\n",
        "def create_doc_vec():\n",
        "\n",
        "  Docs_vec={}\n",
        "  cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "  for group in cat_list:\n",
        "    for filename in glob.glob(\"drive/My Drive/IR4/\"+group+\"/*\"):\n",
        "        #D_vec = [0 for i in range(0,len(Inv_list))]\n",
        "      print(\"filename\",filename[j+1:len(filename)])\n",
        "      D_vec=[]\n",
        "      length=len(filename)\n",
        "      j=0\n",
        "      for k in range(length-1,-1,-1):\n",
        "        if filename[k]=='/':\n",
        "          j=k\n",
        "          break\n",
        "      \n",
        "      for key in Inv.keys():\n",
        "        flag11=0\n",
        "        list1=Inv.get(key)\n",
        "        for dt in list1:\n",
        "          if dt[0]==filename[j+1:len(filename)]:\n",
        "            D_vec.append(dt[1])\n",
        "            flag11=1\n",
        "        if flag11==0:\n",
        "          D_vec.append(0)\n",
        "      print(len(D_vec))\n",
        "      Docs_vec.update({filename[j+1:len(filename)]:D_vec})\n",
        "  return Docs_vec  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C02dpFxp8ydC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Code to dump all the document vectors created in the pickle file called \"Docs_Vec_IR4.pickle\"\n",
        "\n",
        "Docs_vec=create_doc_vec()\n",
        "pickle_out = open(\"Docs_Vec_IR4.pickle\",\"wb\")\n",
        "pickle.dump(Docs_vec, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cPV4Tzfn7uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 8 to execute ##\n",
        "##Code to load all the document vectors from \"Docs_Vec_IR4.pickle\"  ###\n",
        "\n",
        "pickle_in = open(\"drive/My Drive/Docs_Vec_IR4.pickle\",\"rb\")\n",
        "Docs_vec= pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKX0fvW2oDnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 9 to execute ##\n",
        "## Cosine(Q_vec,k) is used to calculate cosine similarity between query vectors and document vectors ###\n",
        "## This function takes 2 paramers Q_vec ::: Query Vector and k ::: Number of results user wants to display ###\n",
        "### This function returns Ranked top k documents with highest cosine similarity with the query vector ###\n",
        "\n",
        "\n",
        "def cosine(Q_vec,k):  \n",
        "  mod_q=0\n",
        "  for item in Q_vec:\n",
        "    mod_q=mod_q+ item**2\n",
        "  mod_q=math.sqrt(mod_q)\n",
        "  Result=[]\n",
        "  for doc in Docs_vec.keys():\n",
        "    D_vec=Docs_vec.get(doc)\n",
        "    mod_d=0\n",
        "    for item in D_vec:\n",
        "      mod_d=mod_d+ item**2\n",
        "    mod_d=math.sqrt(mod_d)\n",
        "    Res=0\n",
        "    for i in range(0,len(D_vec)):\n",
        "      Res=Res+(D_vec[i]*Q_vec[i])\n",
        "    Res=Res/(mod_d*mod_q)\n",
        "    Result.append(tuple([doc,Res,D_vec]))\n",
        "\n",
        "\n",
        "  Result.sort(key = operator.itemgetter(1),reverse=True)\n",
        "  Result1=[]\n",
        "\n",
        "\n",
        "  for i in range(0,k):\n",
        "    Result1.append(Result[i])\n",
        "  return Result1\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drxPWWoJo0Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 10 to execute ##\n",
        "### graph() function is used to plot 2D TSNE graph of the vectors to demonstrate known relevant , non relevan and the query vector.\n",
        "\n",
        "def graph(R_vecs,NR_vecs,Q_vec):\n",
        "    tsne = TSNE(n_components=2, random_state=0,verbose=0, perplexity=40)\n",
        "\n",
        "    vector=[]\n",
        "    labels=[]\n",
        "    color=[]\n",
        "    for item in R_vecs:\n",
        "        vector.append(item)\n",
        "        color.append('m')\n",
        "    for item in NR_vecs:\n",
        "        vector.append(item)\n",
        "        color.append('y')\n",
        "    \n",
        "    vector.append(Q_vec)\n",
        "    color.append('k')\n",
        "    transformed_data = tsne.fit_transform(np.array(vector))\n",
        "    k = np.array(transformed_data)\n",
        "    t = (\"Relevant\", \"Non Relevant\", \"Query\")\n",
        "    plt.scatter(k[:, 0], k[:, 1],c=color,label=\"magenta - Relevant,Yellow - Non Relevant,black - Query Vector \")\n",
        "    plt.title(\"Rocchio Algorithm\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf4pi_ZD09Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 11 to execute ##\n",
        "### calc_PR() is used to plot precision - recall curve for each iteration of relevance feedback ###\n",
        "\n",
        "def calc_PR(rel_array):\n",
        "  precision=[]\n",
        "  recall=[]\n",
        "  i=0\n",
        "  rel=0\n",
        "  total=1000\n",
        "\n",
        "  for item in rel_array:\n",
        "    val=item\n",
        "    rel=rel+val\n",
        "    precision.append(rel/(i+1))\n",
        "    recall.append(rel/total)\n",
        "    i=i+1\n",
        "\n",
        "  print(\"precision: \", precision)\n",
        "  print(\"recall: \", recall)  \n",
        "\n",
        "\n",
        "  \n",
        "  plt.plot(recall,precision) \n",
        "\n",
        "\n",
        "  plt.ylabel('precision') \n",
        "\n",
        "  plt.xlabel('recall') \n",
        "  plt.title('P-R plot') \n",
        "  \n",
        "  plt.show() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPNWsbC2Auja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 12 to execute ##\n",
        "### Function to calculate Average precision for the set of queries ###\n",
        "\n",
        "def AP(rel_array):\n",
        "  precision=[]\n",
        "  i=0\n",
        "  rel=0\n",
        "  \n",
        "\n",
        "  for item in rel_array:\n",
        "    val=item\n",
        "    rel=rel+val\n",
        "    precision.append(rel/(i+1))\n",
        "    i=i+1\n",
        "\n",
        "  ap=0\n",
        "  count=0\n",
        "  j=0\n",
        "  for item in rel_array:\n",
        "    if item==1:\n",
        "      count=count+1\n",
        "      ap=ap+precision[j]  \n",
        "    j=j+1\n",
        "\n",
        "  ap=ap/count\n",
        "  return ap\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr1gL7erDrX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CELL 13 to execute ##\n",
        "### Function to caculate mean average precision MAP ###\n",
        "\n",
        "def MAP(res_arr):\n",
        "  length=len(res_arr[0])\n",
        "  ct=len(res_arr)\n",
        "  for i in range(0,length):\n",
        "    sum=0\n",
        "    for j in range(0,ct):\n",
        "      sum=sum+res_arr[j][i]\n",
        "    print(\"MAP for \",i+1,\" iteration is: \",sum/ct)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "code",
        "id": "MLaCQmnp-o27",
        "outputId": "74281153-d09c-49bf-84f8-c311fe7f7963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "## CELL 14 to execute ##\n",
        "#### Heart string of this code file ###\n",
        "#### this piece of code performs the various tasks with the help of other function ### \n",
        "try :\n",
        "\n",
        "  q=int(input(\"how many queries you wish you input\"))\n",
        "  LIL = [[] for i in range(q)]\n",
        "\n",
        "  file_Dict={1:\"comp.graphics\", 2:\"rec.sport.hockey\", 3:\"sci.med\", 4:\"sci.space\", 5:\"talk.politics.misc\"}\n",
        "  z=0\n",
        "  while q>0:\n",
        "    q=q-1\n",
        "    \n",
        "    query=input(\"Enter your query\")\n",
        "    k=input(\"Enter number of search results you want\")\n",
        "    k=int(k)\n",
        "    print(\"Enter ground truth folder required to plot PR curve in part e: \")\n",
        "    print(\"1:comp.graphics  \", \"2:rec.sport.hockey  \", \"3:sci.med  \", \"4:sci.space  \", \"5:talk.politics.misc\")\n",
        "    print(\"Enter a value from 1-5\")\n",
        "    choice=int(input())\n",
        "\n",
        "\n",
        "    query=query.replace(',','')\n",
        "\n",
        "    query_stem_original=[]\n",
        "\n",
        "    words=tokenizer.tokenize(query)\n",
        "\n",
        "\n",
        "\n",
        "    for w in words:\n",
        "      if w.isdigit():\n",
        "        query_stem_original.append(ps.stem(num2words(w)))\n",
        "      else:  \n",
        "        query_stem_original.append(ps.stem(w))  \n",
        "\n",
        "    query_stem=sorted(set(query_stem_original))\n",
        "\n",
        "    Q_vec=[]\n",
        "\n",
        "    for key in Inv.keys():\n",
        "      if key in query_stem:\n",
        "        tf=0\n",
        "        for t in query_stem_original:\n",
        "          if t==key:\n",
        "            tf=tf+1\n",
        "        df=len(Inv_list.get(key))\n",
        "        df=math.log((Num/df),10)\n",
        "        tf_idf=(1+math.log(1+tf,10))*df\n",
        "        Q_vec.append(tf_idf)\n",
        "      else:\n",
        "        Q_vec.append(0)\n",
        "\n",
        "\n",
        "    Rel_Array=[]\n",
        "    iter=3\n",
        "    rty.clear()\n",
        "    while(iter>0):\n",
        "      iter=iter-1\n",
        "      feed_back=[0 for i in range(0,k)]\n",
        "      Result=cosine(Q_vec,k)\n",
        "      \n",
        "      for item in Result:\n",
        "        flag_rel=False\n",
        "        for filename in glob.glob(\"drive/My Drive/IR4/\"+file_Dict.get(choice)+\"/*\"):\n",
        "          length=len(filename)\n",
        "          j=0\n",
        "          for k1 in range(length-1,-1,-1):\n",
        "            if filename[k1]=='/':\n",
        "              j=k1\n",
        "              break\n",
        "          \n",
        "\n",
        "\n",
        "          if item[0]==filename[j+1:len(filename)]:\n",
        "            flag_rel=True\n",
        "        \n",
        "        if flag_rel==True:\n",
        "          Rel_Array.append(1)\n",
        "        else:\n",
        "          Rel_Array.append(0)\n",
        "\n",
        "      calc_PR(Rel_Array)\n",
        "      ll=AP(Rel_Array)\n",
        "      LIL[z].append(ll)\n",
        "      \n",
        "      for i in range(0,len(Result)):\n",
        "        if Result[i][0] in rty:\n",
        "          print(i,Result[i][0],\"*\")  \n",
        "        else:\n",
        "          print(i,Result[i][0])\n",
        "\n",
        "      nos=input(\"Enter relevant docs list.Please use space to sepate two doc IDs \")\n",
        "      \n",
        "      nos=nos.split()\n",
        "      rel=[]\n",
        "      for item in nos:\n",
        "        rel.append(int(item))\n",
        "      non_rel=[]\n",
        "      for item in range(0,k):\n",
        "        if item not in rel:\n",
        "          non_rel.append(item)\n",
        "      R_vecs=[]\n",
        "      NR_vecs=[]    \n",
        "      R=np.array([0 for i in range(0,len(Q_vec))])\n",
        "      N=np.array([0 for i in range(0,len(Q_vec))])\n",
        "      rty=[]\n",
        "      for item in rel:\n",
        "        rty.append(Result[item][0])\n",
        "        R_vecs.append(np.array(Result[item][2]))\n",
        "        R=np.add(np.array(Result[item][2]),R)\n",
        "        \n",
        "      for item in non_rel:\n",
        "        NR_vecs.append(np.array(Result[item][2]))\n",
        "        N=np.add(np.array(Result[item][2]),N)\n",
        "\n",
        "      N=(N/len(rel))\n",
        "      R=(R/len(non_rel))\n",
        "      Q_vec=Q_vec + 0.7 * R - 0.25*N  \n",
        "      \n",
        "      for item in Q_vec:\n",
        "        if item<0:\n",
        "          item=0\n",
        "      print(Q_vec)\n",
        "      print(\"Average precision of the query for this iteration is :\",ll)\n",
        "      print(\"Please hold tight!!! Mean average precision (MAP) will be displayed after all the feedback iterations of every query\")\n",
        "      \n",
        "      graph(R_vecs,NR_vecs,Q_vec)\n",
        "    z=z+1\n",
        "\n",
        "  MAP(LIL)  \n",
        "except :\n",
        "  print(\"Some exception occured\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how many queries you wish you input1\n",
            "Enter your queryPretty good opinions on biochemistry machines\n",
            "Enter number of search results you want100\n",
            "Enter ground truth folder required to plot PR curve in part e: \n",
            "1:comp.graphics   2:rec.sport.hockey   3:sci.med   4:sci.space   5:talk.politics.misc\n",
            "Enter a value from 1-5\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gT7Mw5UHOHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R28uiNMDHOoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9d543b1-c3d9-4901-d467-66cc3863ef59"
      },
      "source": [
        "print(rty)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['54516', '53935', '54273', '59400', '59411', '38555', '58959', '62410', '178963', '61190']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}