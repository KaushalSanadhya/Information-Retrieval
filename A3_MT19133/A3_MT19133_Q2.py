# -*- coding: utf-8 -*-
"""IR_Assignment_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18arQad3nXsJOsfggSixDR8y02L7WaY7x
"""

nokiimport numpy as np
import pandas as pd
import glob

gd_dict={}

text = open("file.txt","r+",errors='ignore') 
var=(text.read())
var = var.split()
print(var)
cat_list=["alt.atheism","comp.graphics","comp.os.ms-windows.misc","comp.sys.ibm.pc.hardware","comp.sys.mac.hardware","comp.windows.x","misc.forsale","rec.autos","rec.motorcycles","rec.sport.baseball","rec.sport.hockey","sci.cryptm","sci.electronics","sci.med","sci.space","soc.religion.christian","talk.politics.guns","talk.politics.mideast","talk.politics.misc","talk.religion.misc"]
#cat_list=["alt.atheism","comp.graphics","comp.os.ms-windows.misc"]
i=1
for group in cat_list:
  for filename in glob.glob("drive/My Drive/20_newsgroups (1)/20_newsgroups/"+group+"/*"):
    length=len(filename)
    j=0
    for k in range(length-1,-1,-1):
      if filename[k]=='/':
        j=k
        break
    

    gd_dict.update({filename[j+1:len(filename)]:int( var[i])});
    i=i+2

print(gd_dict)

sum=0

for key in gd_dict.keys():
  sum=sum+gd_dict.get(key)

from nltk.stem import PorterStemmer 
from nltk.tokenize import RegexpTokenizer
from nltk.tokenize import word_tokenize 
ps = PorterStemmer() 

tokenizer = RegexpTokenizer(r'\w+')

pip install num2words

import nltk
nltk.download('punkt')

import glob
import csv
from nltk.tokenize import RegexpTokenizer
from nltk.stem import PorterStemmer 
from num2words import num2words
from nltk.tokenize import word_tokenize 
ps = PorterStemmer() 
tokenizer = RegexpTokenizer(r'\w+')
q_stem=[]
query=input("please input your query")
query=query.replace(',','')
    
q_words=tokenizer.tokenize(query)
for q_w in q_words:
  if q_w.isdigit():
  
    q_stem.append(ps.stem(num2words(q_w)))
  else:
    q_stem.append(ps.stem(q_w))
print(q_stem)

####Inverted List####
import os
from num2words import num2words
Inv_list = {} 
for group in cat_list:
  for filename in glob.glob("drive/My Drive/20_newsgroups (1)/20_newsgroups/"+group+"/*"):
    #print(filename)
    length=len(filename)
    j=0
    for k in range(length-1,-1,-1):
      if filename[k]=='/':
        j=k
        break
    print(filename[j+1:len(filename)])
    if not os.path.isdir(filename):
      text = open(filename,"r+",errors='ignore') 
      var=(text.read())
      var=var.replace(',','')

      words=tokenizer.tokenize(var)
      Words=[]
      for w in words:
        if w.isdigit():
  
          Words.append(ps.stem(num2words(w)))
        else:
          Words.append(ps.stem(w))

      print(filename[j+1:len(filename)])
      for word in Words:
        
        if word not in Inv_list.keys():
          List=[(filename[j+1:len(filename)],gd_dict.get(filename[j+1:len(filename)]),1)]
          Inv_list.update({word:List})
        else:
          val=Inv_list.get(word)
          flag=0
          i=0
          c=0
          for v in val:
            if v[0] ==filename[j+1:len(filename)]:

              flag=1
              c=i
              break
            i=i+1

          if flag==0:
            val.append(tuple([filename[j+1:len(filename)],gd_dict.get(filename[j+1:len(filename)]),1]))
          if flag==1:
            temp=val[c]
            val.pop(c)
            t=tuple([temp[0],temp[1],temp[2]+1])
            val.append(t)


import pickle

pickle_out = open("myInverted_List.pickle","wb")
pickle.dump(Inv_list, pickle_out)
pickle_out.close()

Inv={}
def last(n):
  return n[1]   

for key in Inv_list.keys():
  temp=Inv_list.get(key)
  temp=sorted(temp, key = last,reverse=True)
  Inv.update({key:temp})

for item in Inv.keys():
  print(len(Inv.get(item)))

### Finding High and low of terms in inverted index #####

X=[]

for term in Inv.keys():
  print(term)
  High=[]
  Low=[]
  List=Inv.get(term)
  temp=[]
  for item in List:
    temp.append(item[2])
  res = sorted(range(len(temp)), key = lambda sub: temp[sub])[-5:]
  for i in range(0,len(res)):
    High.append(List[i][0])
  
  for item in Inv.get(term):
    if item[0] not in High:
      Low.append(item[0])

  X.append(tuple([term,High,Low]))

print((X[1100]))

import glob
import csv
from nltk.tokenize import RegexpTokenizer
from nltk.stem import PorterStemmer 
from nltk.tokenize import word_tokenize 
from num2words import num2words

ps = PorterStemmer() 
  
import os
count=0
count1=0
Dict_tokens = {} 
Dict_docs={}
Dict_df={}
Dict_flag={}
tokenizer = RegexpTokenizer(r'\w+')
for group in ["alt.atheism"]:
  for filename in glob.glob("drive/My Drive/20_newsgroups (1)/20_newsgroups/"+group+"/*"):
    if not os.path.isdir(filename):

      for term in Dict_flag:
        Dict_flag.pop(term)
        Dict_flag.update({term:0})
      
      if filename not in Dict_docs:
        Dict_docs.update({filename:count1})
        count1=count1+1
      text = open(filename,"r+",errors='ignore') 
      var=(text.read())
      var=var.replace(',','')

      words=tokenizer.tokenize(var)
      Temp=[]
      for w in words:
        if w.isdigit():
          w=num2words(w)      
        Temp.append(ps.stem(w))  
      for word in Temp:
        if word not in Dict_tokens:
          Dict_tokens.update({word:count})
          count=count+1
        if word not in Dict_df:
          Dict_df.update({word:1})
          #print(word)
          Dict_flag.update({word:1})
        else :
          if Dict_flag.get(word) == 0:
            c=Dict_df.get(word)
            c=c+1
            Dict_df.pop(word)
            Dict_df.update({word:c})
            Dict_flag.update({word:1})

import math

def cosine(query):

  #query=input("Enter your query")
  query=query.replace(',','')

  query_stem_original=[]

  words=tokenizer.tokenize(query)

  for w in words:
    if w.isdigit():
      query_stem_original.append(ps.stem(num2words(w)))
    else:  
      query_stem_original.append(ps.stem(w))  
    
  query_stem = list(dict.fromkeys(query_stem_original))
  Q_A=[]


  print(query_stem)
  for t in query_stem:

    count=0
    tf_idf=0
    for term in query_stem_original:
      if t==term:
        count=count+1
    #tf=1+math.log(1+count)
    tf=count
    tf_idf=tf*math.log(len(Dict_docs)/int(Dict_df.get(t)))
    Q_A.append(tf_idf)
    

  Q_A=np.array(Q_A)
  print(Q_A)
  mod_q=0
  for item in Q_A:
    mod_q=mod_q+ item**2

  mod_q=math.sqrt(mod_q)

  Dict_sim={}
  Q_A_new=[]
  for item in Q_A:
    Q_A_new.append(item/mod_q)

  for doc in Dict_docs:
    Temp=[]
    D_A=[]
    text = open(doc,"r+",errors='ignore') 
    var=(text.read())
    var=var.replace(',','')

    words=tokenizer.tokenize(var)
    
    for w in words:
      if w.isdigit():
        Temp.append(ps.stem(num2words(w)))
      else:

        Temp.append(ps.stem(w))  
    tf_idf=0
    for q_t in query_stem:
      count=0
      if q_t in Temp:
        
        for term in Temp:
          if q_t ==term:
            count=count+1
      #tf=1+math.log(1+count)
      tf=count
      tf_idf=( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) )
      D_A.append(tf_idf)
    D_A=np.array(D_A)
    mod_d=0
    D_A_new=[]
    for item in D_A:
      mod_d=mod_d+ item**2

    mod_d=math.sqrt(mod_d)

    for item in D_A:
      D_A_new.append(item/mod_d)

    similarity=0
    for i in range(0,len(D_A)):

      similarity=similarity+ (D_A_new[i]*Q_A_new[i])

    #similarity=similarity

    length=len(filename)
    j=0
    for k in range(length-1,-1,-1):
      if filename[k]=='/':
        j=k
        break

    Dict_sim.update({doc[j+1:len(filename)]:similarity})
    

  import operator
  Dict_sim= dict( sorted(Dict_sim.items(), key=operator.itemgetter(1),reverse=True)  ) 
  return Dict_sim

print(X[6])

query=input("Enter your query")
k=input("Enter number of search results you want")
k=int(k)
query=query.replace(',','')

query_stem_original=[]

words=tokenizer.tokenize(query)

for w in words:
  if w.isdigit():
    query_stem_original.append(ps.stem(num2words(w)))
  else:  
    query_stem_original.append(ps.stem(w))  
    
query_stem = list(dict.fromkeys(query_stem_original))

U=set()
for qt in query_stem:
  for item in X:
    if item[0]==qt:
      U=U.union(set(item[1]))
order=[]
Dict_sim=cosine(query)
for doc in U:
  gd=gd_dict.get(doc)
  cos=Dict_sim.get(doc)
  order.append(tuple([doc,(gd/sum)+cos]))
order=sorted(order, key = lambda x: x[1],reverse=True)


order1=[]
if len(order)<k :
  U1=set()
  for qt in query_stem:
    for item in X:
      if item[0]==qt:
        U1=U1.union(set(item[2]))
  Dict_sim=cosine(query)
  for doc in U1:
    gd=gd_dict.get(doc)
    cos=Dict_sim.get(doc)
    order1.append(tuple([doc,(gd/sum)+cos]))

  

  for i in range(0,k-len(order)):
    order.append(order1[i])
  order=sorted(order, key = lambda x: x[1],reverse=True)
  print(order)
else:
  print(order)

##############################################################################
##############################################################################
##############################################################################
##############################################################################

import numpy as np
import pandas as pd
import glob

text = open("drive/My Drive/A3_Q2.txt","r+",errors='ignore') 
var=(text.read())
var = var.split()
Data=[]
j=0 
k=0
for i in range(0,int(len(var)/138)):
  if i ==0:
    j=i
    k=j+138
  else :
    j=k
    k=j+138
  temp=tuple([var[j:k]])
  Data.append(temp)

import numpy as np
import math
Data_q4=[]

for item in Data:
  if item[0][1]=='qid:4':
    Data_q4.append(item)

for item in Data_q4:
  item[0][0]=int(item[0][0])
  

Data_q4_sorted=sorted(Data_q4, key = lambda x: x[0],reverse=True)
DCG_max=0

for i in range(0,len(Data_q4)):
  DCG_max=DCG_max+(Data_q4_sorted[i][0][0]/math.log(i+2,2))

print("DCG_max",DCG_max)

zeros=0
ones=0
twos=0
threes=0
fours=0

for item in Data_q4:
  if item[0][0]==0:
    zeros=zeros+1
  if item[0][0]==1:
    ones=ones+1
  if item[0][0]==2:
    twos=twos+1
  if item[0][0]==3:
    threes=threes+1
  if item[0][0]==4:
    fours=fours+1
print("ones",ones) 
print("twos",twos)
print("threes",threes)
print("fours",fours)   
permutations=(math.factorial(fours)*math.factorial(threes)*math.factorial(twos)*math.factorial(ones)*math.factorial(zeros))
print("Total Permutations",permutations)

#### nDCG at 50  ###

def NDCG(k):

  DCG=0
  IDCG=0
  Data_q4_k=Data_q4[0:k]
  Data_q4_k_sorted=Data_q4_sorted[0:k]
  for i in range(0,len(Data_q4_k)):
    DCG=DCG+(Data_q4_k[i][0][0]/math.log(i+2,2))

  for i in range(0,len(Data_q4_k_sorted)):
    IDCG=IDCG+(Data_q4_k_sorted[i][0][0]/math.log(i+2,2))

  print("nDCG at",k," = ",DCG/IDCG)


k=int(input("Enter the value of k"))
NDCG(k)

##Execute only once 
for item in Data_q4:
  
  length=len(item[0][76])
  item[0][76]=float(item[0][76][3:length])

#execute only once
Data_sorted=sorted(Data_q4, key = lambda x: x[0][76],reverse=True)

for item in Data_sorted:
  rel=int(item[0][0])
  if rel >0 :
    print("prev",item[0][0])
    item[0][0]=1
    print("after",item[0][0])
  else:
    print("prev",item[0][0])
    item[0][0]=0
    print("after",item[0][0])

precision=[]
recall=[]
i=0
rel=0
total=0

for item in Data_sorted:
  val=item[0][0]
  if val ==1 :
    total=total+1

for item in Data_sorted:
  val=item[0][0]
  rel=rel+val
  precision.append(rel/(i+1))
  recall.append(rel/total)
  i=i+1

print(precision)
print(recall)  


import matplotlib.pyplot as plt 

plt.plot(recall,precision) 


plt.ylabel('precision') 

plt.xlabel('recall') 
plt.title('P-R plot') 
 
plt.show()