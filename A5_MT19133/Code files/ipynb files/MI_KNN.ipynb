{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR5_MI_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwMougGPuSsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 0 ##\n",
        "\n",
        "cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "import pickle\n",
        "\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# UNCOMMENT these three pickle files for executing the code for (80:20) split. Give path to the pickled files.  #\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_list(80:20).pickle FILE\",\"rb\")\n",
        "#classes_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF Global(80:20).pickle FILE\",\"rb\")\n",
        "#GLOBAL =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_test_list(80:20).pickle FILE\",\"rb\")\n",
        "#classes_test_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF MI(80:20).pickle FILE\",\"rb\")\n",
        "#MI =pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# UNCOMMENT these three pickle files for executing the code for 70:30 split. Give path to the pickled files. #\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_list(70:30).pickle FILE\",\"rb\")\n",
        "#classes_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF Global(70:30).pickle FILE\",\"rb\")\n",
        "#GLOBAL =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_test_list(70:30).pickle FILE\",\"rb\")\n",
        "#classes_test_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF MI(70:30).pickle FILE\",\"rb\")\n",
        "#MI =pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# UNCOMMENT these three pickle files for executing the code for (50:50) split. Give path to the pickled files. #\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_list(50:50).pickle FILE\",\"rb\")\n",
        "#classes_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF Global(50:50).pickle FILE\",\"rb\")\n",
        "#GLOBAL =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF classes_test_list(50:50).pickle FILE\",\"rb\")\n",
        "#classes_test_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"PATH OF MI(50:50).pickle FILE\",\"rb\")\n",
        "#MI =pickle.load(pickle_in)\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#Execution sequence of this python  code using pickled results\n",
        "\n",
        "# Cell 1 --> Cell 2 --> Cell 3 -->Cell 4-->cell 10-->cell 11-->cell 12--->Cell 13--> Cell 14 --> Cell 15-->Cell 16--->Cell 17--->cell 18\n",
        "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if1N8mz0cql5",
        "colab_type": "code",
        "outputId": "281614b7-1ee5-45f1-c7bd-4151781bd232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "### Cell 1 ###\n",
        "##importing  nltk##\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCNM801rc0Cu",
        "colab_type": "code",
        "outputId": "62f44d26-344e-4335-8850-a1f93fa28d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Cell 2 #\n",
        "##installing num2words ##\n",
        "pip install num2words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting num2words\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n",
            "Installing collected packages: num2words\n",
            "Successfully installed num2words-0.5.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcQJn4x1c2Nc",
        "colab_type": "code",
        "outputId": "1ce2fc64-5023-4696-a4b4-288a673ce955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Cell 3 #\n",
        "#Importing all esentials#\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize \n",
        "import numpy as np\n",
        "import glob\n",
        "from collections import Counter \n",
        "from sklearn.utils import shuffle  \n",
        "import os\n",
        "from num2words import num2words\n",
        "from nltk.corpus import stopwords \n",
        "import pickle\n",
        "import math\n",
        "import operator\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd  \n",
        "\n",
        "ps = PorterStemmer() \n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brAQPjBAc5Pc",
        "colab_type": "code",
        "outputId": "b51fc2ae-d12a-42d8-8dc4-3e01b7bc2294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "## CELL 4  ##\n",
        "## Download stopwords ##\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbPUaeK4c7G5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 5 ##\n",
        "##Splitting into Test & Train RANDOMLY using Test Train Split and shuffle ###\n",
        "\n",
        "\n",
        "\n",
        "Data=pd.DataFrame(columns = [\"file_name\", \"class\"])\n",
        "cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "\n",
        "\n",
        "for group in cat_list:\n",
        "  for filename in glob.glob(\"drive/My Drive/IR4/\"+group+\"/*\"):\n",
        "    \n",
        "    length=len(filename)\n",
        "    j=0\n",
        "    for k in range(length-1,-1,-1):\n",
        "      if filename[k]=='/':\n",
        "        j=k\n",
        "        break\n",
        "  \n",
        "    Data=Data.append({\"file_name\":filename[j+1:len(filename)],\"class\":group},ignore_index=True)\n",
        "\n",
        "##Shuffling and split ##\n",
        "Data = shuffle(Data)\n",
        "\n",
        "x=Data[\"file_name\"]\n",
        "y=Data[\"class\"]\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLY4pwpTc-xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 6 ##\n",
        "## Pre-processing Train Docs ###\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "GLOBAL=[]\n",
        "classes_list={}\n",
        "for group in cat_list:\n",
        "  global_doc=[]\n",
        "  for filename in glob.glob(\"drive/My Drive/IR4/\"+group+\"/*\"):\n",
        "    \n",
        "    length=len(filename)\n",
        "    j=0\n",
        "    for k in range(length-1,-1,-1):\n",
        "      if filename[k]=='/':\n",
        "        j=k\n",
        "        break\n",
        "    print(filename[j+1:len(filename)])\n",
        "    if filename[j+1:len(filename)] in list(xTrain):\n",
        "      if not os.path.isdir(filename):\n",
        "        text = open(filename,\"r+\",errors='ignore') \n",
        "        var=(text.read())\n",
        "        var=var.replace(',','')\n",
        "        words_tokens=tokenizer.tokenize(var)\n",
        "        words = [w for w in words_tokens if not w in stop_words] \n",
        "      \n",
        "        Words=[]\n",
        "        for w in words:\n",
        "          if w.isdigit():\n",
        "            Words.append(ps.stem(num2words(w)))\n",
        "            GLOBAL.append(ps.stem(num2words(w)))\n",
        "          else:\n",
        "            Words.append(ps.stem(w))\n",
        "            GLOBAL.append(ps.stem(w))\n",
        "      global_doc.append(Words)\n",
        "  classes_list.update({group:global_doc})\n",
        "\n",
        "\n",
        "#pickle_out = open(\"drive/My Drive/classes_list(80:20).pickle\",\"wb\")\n",
        "#pickle.dump(classes_list, pickle_out)\n",
        "#pickle_out.close()\n",
        "\n",
        "\n",
        "#pickle_out = open(\"drive/My Drive/Global(80:20).pickle\",\"wb\")\n",
        "#pickle.dump(classes_list, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUfQbxE2dJFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 7 ##\n",
        "### Calculating MI for each Tuple(term,class) ####\n",
        "\n",
        "MI=[]\n",
        "\n",
        "Global_unique=np.unique(GLOBAL) #all terms of all the classes\n",
        "\n",
        "for term in Global_unique:\n",
        "  for clas in cat_list:\n",
        "    N11=0\n",
        "    N10=0\n",
        "    N01=0\n",
        "    N00=0\n",
        "\n",
        "    for key in classes_list.keys():\n",
        "      docs=classes_list.get(key)\n",
        "      for doc in docs:\n",
        "        if term in doc and key ==clas:\n",
        "          N11=N11+1\n",
        "        if term in doc and key !=clas:\n",
        "          N10=N10+1\n",
        "        if term not in doc and key ==clas:\n",
        "          N01=N01+1\n",
        "        if term not in doc and key !=clas:\n",
        "          N00=N00+1\n",
        "    N00=N00+0.0001\n",
        "    N01=N01+0.0001\n",
        "    N10=N10+0.0001\n",
        "    N11=N11+0.0001      \n",
        "    N=N00+N11+N01+N10\n",
        "    \n",
        "\n",
        "    val=(N11/N)*math.log(((N*N11)/((N11+N10)*(N01+N11)))+0.0001,2) + (N01/N)*math.log(((N*N01)/((N01+N00)*(N01+N11)))+0.0001,2) + (N10/N)*math.log(((N*N10)/((N11+N10)*(N00+N10)))+0.0001,2) + (N00/N)*math.log(((N*N00)/((N01+N00)*(N00+N10)))+0.0001,2)\n",
        "    print(term,val)\n",
        "    MI.append(tuple([term,clas,val]))\n",
        "\n",
        "#### selecting the value of number of features (K) ###\n",
        "### Feature Selection using TF-IDF ###\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ1LABL7BJo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 8 ##\n",
        "\n",
        "#cat_list=[\"comp.graphics\",\"rec.sport.hockey\",\"sci.med\",\"sci.space\",\"talk.politics.misc\"]\n",
        "#pickle_in = open(\"drive/My Drive/classes_list(70:30).pickle\",\"rb\")\n",
        "#classes_list =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"drive/My Drive/Global(70:30).pickle\",\"rb\")\n",
        "#GLOBAL =pickle.load(pickle_in)\n",
        "\n",
        "#pickle_in = open(\"drive/My Drive/xTest(70:30).pickle\",\"rb\")\n",
        "#xTest =pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "#pickle_in = open(\"drive/My Drive/classes_test_list(70:30).pickle\",\"rb\")\n",
        "#classes_test_list =pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A4vyCXTdN1W",
        "colab_type": "code",
        "outputId": "494a2db3-b8ad-4092-b36b-4f2c4f08ef5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Cell 9 ##\n",
        "\n",
        "\n",
        "#MI=[]\n",
        "#file = open(\"drive/My Drive/MI_1(80:20).pickle\", 'rb')      \n",
        "#MI1 = pickle.load(file) \n",
        "#file = open(\"drive/My Drive/MI_2(80:20).pickle\", 'rb')      \n",
        "#MI2 = pickle.load(file) \n",
        "#file = open(\"drive/My Drive/MI_3(80:20).pickle\", 'rb')      \n",
        "#MI3 = pickle.load(file) \n",
        "#file = open(\"drive/My Drive/MI_4(80:20).pickle\", 'rb')      \n",
        "#MI4 = pickle.load(file) \n",
        "#file = open(\"drive/My Drive/MI_5(80:20).pickle\", 'rb')      \n",
        "#MI5 = pickle.load(file) \n",
        "#file = open(\"drive/My Drive/MI_6(80:20).pickle\", 'rb')      \n",
        "#MI6 = pickle.load(file)\n",
        "\n",
        "#for item in range(0,len(MI1)):\n",
        "#  MI.append(MI1[item])\n",
        "#  MI.append(MI2[item])\n",
        "#  MI.append(MI3[item])\n",
        "#  MI.append(MI4[item])\n",
        "#  MI.append(MI5[item])\n",
        "#  MI.append(MI6[item])\n",
        "\n",
        "#print(len(MI))\n",
        "\n",
        "#pickle_out = open(\"drive/My Drive/MI(80:20).pickle\",\"wb\")\n",
        "#pickle.dump(MI, pickle_out)\n",
        "#pickle_out.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "261180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBEFgf2ZdRy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 10 ##\n",
        "### Further proceesing of MI.Please note that I have selected 1/5 of total features for my calculations ##\n",
        "Global_unique=np.unique(GLOBAL)\n",
        "MI1=[]\n",
        "MI2=[]\n",
        "MI3=[]\n",
        "MI4=[]\n",
        "MI5=[]\n",
        "\n",
        "for item in MI:\n",
        "  if item[1]==cat_list[0]:\n",
        "    MI1.append(item)\n",
        "  if item[1]==cat_list[1]:\n",
        "    MI2.append(item)\n",
        "  if item[1]==cat_list[2]:\n",
        "    MI3.append(item)\n",
        "  if item[1]==cat_list[3]:\n",
        "    MI4.append(item)\n",
        "  if item[1]==cat_list[4]:\n",
        "    MI5.append(item)\n",
        "\n",
        "MI1.sort(key=lambda elem : elem[2],reverse=True)\n",
        "MI2.sort(key=lambda elem : elem[2],reverse=True)\n",
        "MI3.sort(key=lambda elem : elem[2],reverse=True)\n",
        "MI4.sort(key=lambda elem : elem[2],reverse=True)\n",
        "MI5.sort(key=lambda elem : elem[2],reverse=True)\n",
        "\n",
        "length=int(len(MI1)/5)\n",
        "\n",
        "Mutual_info=[]\n",
        "Mutual_info.append(MI1[0:length])\n",
        "Mutual_info.append(MI2[0:length])\n",
        "Mutual_info.append(MI3[0:length])\n",
        "Mutual_info.append(MI4[0:length])\n",
        "Mutual_info.append(MI5[0:length])\n",
        "################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnVFdA_ZLD44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 11 ##\n",
        "##  Making tuple (class,feature vector) for each training doc ##\n",
        "train_vecs=[]\n",
        "selected_features=[]\n",
        "\n",
        "## making union of all selected features from each class ###\n",
        "for cls in Mutual_info:\n",
        "  for item in cls:\n",
        "    selected_features.append(item[0])\n",
        "\n",
        "selected_features=set(selected_features)\n",
        "selected_features=list(selected_features)\n",
        "\n",
        "\n",
        "\n",
        "for key in classes_list.keys():\n",
        "\n",
        "  docs=classes_list.get(key)\n",
        "  for doc in docs:\n",
        "    #print(doc)\n",
        "    vec=[]\n",
        "    for feature in selected_features:\n",
        "      vec.append(doc.count(feature))\n",
        "    train_vecs.append(tuple([key,vec]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mH4OF69Lf_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 12 ##\n",
        "##  Making tuple (class,feature vector) for each Testing doc ##\n",
        "\n",
        "test_vecs=[]\n",
        "\n",
        "for key in classes_test_list.keys():\n",
        "\n",
        "  docs=classes_test_list.get(key)\n",
        "  for doc in docs:\n",
        "    print(doc)\n",
        "    vec=[]\n",
        "    for feature in selected_features:\n",
        "      vec.append(doc.count(feature))\n",
        "    test_vecs.append(tuple([key,vec]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCV83yarLi1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 13 ##\n",
        "#### Matrix multiplication of Test and Train Docs for computing Cosing similarity###\n",
        "TestV=[]\n",
        "TrainV=[]\n",
        "for test in test_vecs:\n",
        "  TestV.append(test[1])\n",
        "\n",
        "for train in train_vecs:\n",
        "  TrainV.append(train[1])\n",
        "\n",
        "TestV=np.array(TestV)\n",
        "TrainV=np.array(TrainV)\n",
        "dot=np.dot(TestV,TrainV.T)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4O4aKWlLpJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 14 ##\n",
        "## Computing Similarity Matrix from above matrix multiplication ##\n",
        "similarity_matrix=[]\n",
        "for i in range(0,len(test_vecs)):\n",
        "  mag_test=np.linalg.norm(TestV[i])\n",
        "  print(i)\n",
        "  list1=dot[i]\n",
        "  list1=list1/mag_test\n",
        "  #print(len(list))\n",
        "  temp=[]\n",
        "  for j in range(0,len(train_vecs)):\n",
        "    \n",
        "    mag_train=np.linalg.norm(TrainV[j])\n",
        "    temp.append(tuple([j,list1[j]/mag_train]))\n",
        "\n",
        "  similarity_matrix.append(temp)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-frlwM3aLtXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 15 ##\n",
        "#similarity_matrix=dot\n",
        "#pickle_out = open(\"drive/My Drive/similarity_matrix_MI_KNN(80:20).pickle\",\"wb\")\n",
        "#pickle.dump(similarity_matrix, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAj10hgCLv3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 16 ##\n",
        "## ## KNN logic##\n",
        "import statistics \n",
        "  \n",
        "i=0\n",
        "ct=0\n",
        "actual=[]\n",
        "predicted=[]\n",
        "for test in similarity_matrix:\n",
        "  #print(test\n",
        "  #print(item)\n",
        "  \n",
        "  item=sorted(test, key=lambda tup: tup[1],reverse=True)\n",
        "\n",
        "  ## In order to select the k value of KNN change the second value of the below line of code. Say for K=5 below line will be--> item=item[0:5] \n",
        "  ## For K=3 below line will be--> item=item[0:3]  ###\n",
        "\n",
        "  item=item[0:5]\n",
        "  vecs=[]\n",
        "  for it in item:\n",
        "    x=it[0]\n",
        "    vecs.append(train_vecs[x][0])\n",
        "\n",
        "  res=Counter(vecs)\n",
        "  \n",
        "  class1=res.most_common(1)[0][0]\n",
        "  predicted.append(class1)\n",
        "  actual.append(test_vecs[i][0])\n",
        "  if class1==test_vecs[i][0]:\n",
        "    ct=ct+1\n",
        "  i=i+1\n",
        "acrcy=((ct*100)/len(similarity_matrix))\n",
        "print(\"accuracy= \",acrcy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiuT2vp1L0JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 17 ##\n",
        "## Printing Confusion Matrix ##\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "CM=confusion_matrix(actual, predicted)\n",
        "print(CM)\n",
        "\n",
        "\n",
        "##pickle_out = open(\"drive/My Drive/confusion_matrix_TFIDF_KNN(k=5)(80:20).pickle\",\"wb\")\n",
        "#ickle.dump(CM, pickle_out)\n",
        "#pickle_out.close()\n",
        "\n",
        "\n",
        "#pickle_out = open(\"drive/My Drive/accuracy_TFIDF_KNN(k=5)(80:20).pickle\",\"wb\")\n",
        "#pickle.dump(acrcy, pickle_out)\n",
        "#pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F83I-VgYH6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cell 18 ##\n",
        "## give value of accuracy in list y [] to plot graph for \"Number of neighbours vs accuracy in MI & KNN\"  ###\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        "x=[1,3,5]\n",
        "y=[]  ### Values dal yaha pe ###\n",
        "tick_label = ['K=1', 'K=3', 'K=5'] \n",
        "\n",
        "plt.bar(x,y, tick_label = tick_label, \n",
        "\t\twidth = 0.8, color = ['red', 'green','blue']) \n",
        "\n",
        "\n",
        "plt.xlabel('number of neighbours') \n",
        "\n",
        "plt.ylabel('accuracy') \n",
        "\n",
        "plt.title('Number of neighbours vs accuracy in MI & KNN') \n",
        "plt.ylim(91,95) \n",
        "#plt.xlim(1,8) \n",
        "\n",
        "plt.show() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFnanv84bvah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}