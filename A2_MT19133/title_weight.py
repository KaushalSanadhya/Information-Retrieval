# -*- coding: utf-8 -*-
"""IR_2_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11fifWNmzWqhuKIEgA6mi0GSIO7W9bYyo
"""

import nltk
nltk.download('punkt')

from nltk.stem import PorterStemmer 
from nltk.tokenize import RegexpTokenizer
from nltk.tokenize import word_tokenize 
ps = PorterStemmer() 

tokenizer = RegexpTokenizer(r'\w+')

text = open("sample_data/stopwords.txt","r+",errors='ignore') 
var=(text.read())
words=tokenizer.tokenize(var)
stop_words=[]

for word in words:
  stop_words.append(ps.stem(word))

print(stop_words)

pip install num2words

import glob
import csv
from nltk.tokenize import RegexpTokenizer
from nltk.stem import PorterStemmer 
from nltk.tokenize import word_tokenize 
from num2words import num2words

ps = PorterStemmer() 
  
import os
count=0
count1=0
Dict_tokens = {} 
Dict_docs={}
Dict_df={}
Dict_flag={}
tokenizer = RegexpTokenizer(r'\w+')
for filename in glob.glob("*"):
  if not os.path.isdir(filename):

    for term in Dict_flag:
      Dict_flag.pop(term)
      Dict_flag.update({term:0})
    
    if filename not in Dict_docs:
      Dict_docs.update({filename:count1})
      count1=count1+1
    text = open(filename,"r+",errors='ignore') 
    var=(text.read())
    var=var.replace(',','')

    words=tokenizer.tokenize(var)
    Temp=[]
    for w in words:
      if w.isdigit():
        w=num2words(w)      
      Temp.append(ps.stem(w))  
    for word in Temp:
      if word not in Dict_tokens:
        Dict_tokens.update({word:count})
        count=count+1
      if word not in Dict_df:
        Dict_df.update({word:1})
        #print(word)
        Dict_flag.update({word:1})
      else :
        if Dict_flag.get(word) == 0:
          c=Dict_df.get(word)
          c=c+1
          Dict_df.pop(word)
          Dict_df.update({word:c})
          Dict_flag.update({word:1})

print(Dict_tokens)

print(Dict_df)

###First Variation####
import math
from num2words import num2words
query=input("Enter your query")
query=query.replace(',','')
k=input("How many top results you wish to find")
k=int(k)
query_stem_original=[]

words=tokenizer.tokenize(query)

for w in words:
  if w.isdigit():
  
    query_stem_original.append(ps.stem(num2words(w))) 
  else:
    query_stem_original.append(ps.stem(w))  
  
query_stem = list(dict.fromkeys(query_stem_original))
global_array={}

for doc in Dict_docs:
  Temp=[]
  text = open(doc,"r+",errors='ignore') 
  var=(text.read())
  var=var.replace(',','')

  words=tokenizer.tokenize(var)
  
  for w in words:
    if w.isdigit():
      Temp.append(ps.stem(num2words(w))) 
    else:
      Temp.append(ps.stem(w))  
  tf_idf=0
  for q_t in query_stem:
    count=0
    if q_t in Temp:
      
      for term in Temp:
        if q_t ==term:
          count=count+1
    tf=count
    #print(doc)
    title=Dict_map.get(doc)
    title_words=tokenizer.tokenize(title)
    TW=[]
    for w in title_words:
      if w.isdigit():
        TW.append(ps.stem(num2words(w))) 
      else:
        TW.append(ps.stem(w))  
    
  

    if q_t not in stop_words and q_t in TW: 
      tf_idf=tf_idf +(0.7* ( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) ))
    if q_t not in TW: 
      tf_idf=tf_idf + (0.3*( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) ))
    
  #print(tf_idf)  
  global_array.update({doc:tf_idf})

##################################
print(query_stem)
#print(global_array)                                         
import operator
Dict= dict( sorted(global_array.items(), key=operator.itemgetter(1),reverse=True))
print(Dict) 
for item in Dict:
  print(item)
  k=k-1
  if k<=0:
    break

#print(Dict.get('alissadl.txt'))

print(Dict.get('17.lws'))

###Variation 2 
##tf (logarithm) 1 + log(tft,d)
###idf =1
from num2words import num2words
import math
query=input("Enter your query")
query=query.replace(',','')
k=input("How many top results you wish to find")
k=int(k)
query_stem_original=[]

words=tokenizer.tokenize(query)

for w in words:
  if w.isdigit():
  
    query_stem_original.append(ps.stem(num2words(w))) 
  else:
    query_stem_original.append(ps.stem(w))  
  
query_stem = list(dict.fromkeys(query_stem_original))
global_array={}

for doc in Dict_docs:
  Temp=[]
  text = open(doc,"r+",errors='ignore') 
  var=(text.read())
  var=var.replace(',','')

  words=tokenizer.tokenize(var)
  
  for w in words:
    if w.isdigit():
      Temp.append(ps.stem(num2words(w))) 
    else:
      Temp.append(ps.stem(w))  
    
  tf_idf=0
  for q_t in query_stem:
    count=0
    if q_t in Temp:
      
      for term in Temp:
        if q_t ==term:
          count=count+1
    tf=1+math.log(1+count)
    
    title=Dict_map.get(doc)
    title_words=tokenizer.tokenize(title)
    TW=[]
    for w in title_words:
      if w.isdigit():
        TW.append(ps.stem(num2words(w))) 
      else:
        TW.append(ps.stem(w))  
    
  

    if q_t not in stop_words and q_t in TW: 
      tf_idf=tf_idf +(0.7* ( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t)) )))

    if q_t not in TW: 
      tf_idf=tf_idf +(0.3* ( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t)) )))
    



  global_array.update({doc:tf_idf})


##################################

                                         
import operator
Dict= dict( sorted(global_array.items(), key=operator.itemgetter(1),reverse=True))
print(Dict) 
for item in Dict:
  print(item)
  k=k-1
  if k<=0:
    break

###Variation 3 
##tf (boolean) 
###idf =(logrithmic)
from num2words import num2words
import math
query=input("Enter your query")
query=query.replace(',','')
k=input("How many top results you wish to find")
k=int(k)
query_stem_original=[]

words=tokenizer.tokenize(query)

for w in words:
  if w.isdigit():
  
    query_stem_original.append(ps.stem(num2words(w))) 
  else:
    query_stem_original.append(ps.stem(w))  
  
query_stem = list(dict.fromkeys(query_stem_original))
global_array={}

for doc in Dict_docs:
  Temp=[]
  text = open(doc,"r+",errors='ignore') 
  var=(text.read())
  var=var.replace(',','')

  words=tokenizer.tokenize(var)
  
  for w in words:
    if w.isdigit():
      Temp.append(ps.stem(num2words(w))) 
    else:
      Temp.append(ps.stem(w))  
    
  tf_idf=0
  for q_t in query_stem:
    count=0
    if q_t in Temp:
      
      for term in Temp:
        if q_t ==term:
          count=count+1
    if count > 0:
      tf=1
    else:
      tf=0
    
    title=Dict_map.get(doc)
    title_words=tokenizer.tokenize(title)
    TW=[]
    for w in title_words:
      if w.isdigit():
        TW.append(ps.stem(num2words(w))) 
      else:
        TW.append(ps.stem(w))  
    
  

    if q_t not in stop_words and q_t in TW: 
      tf_idf=tf_idf +(0.7* ( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t)) )))

    if q_t not in TW: 
      tf_idf=tf_idf +(0.3* ( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t)) )))
    


 
  global_array.update({doc:tf_idf})


##################################

                                         
import operator
Dict= dict( sorted(global_array.items(), key=operator.itemgetter(1),reverse=True))
print(Dict) 
for item in Dict:
  print(item)
  k=k-1
  if k<=0:
    break

query=input("Enter your query")
query=query.replace(',','')

query_stem_original=[]

words=tokenizer.tokenize(query)

for w in words:
  if w.isdigit():
    query_stem_original.append(ps.stem(num2words(w)))
  else:  
    query_stem_original.append(ps.stem(w))  
  
query_stem = list(dict.fromkeys(query_stem_original))
Q_A=[]


print(query_stem)
for t in query_stem:

  count=0
  tf_idf=0
  for term in query_stem_original:
    if t==term:
      count=count+1
  #tf=1+math.log(1+count)
  tf=count
  tf_idf=tf*math.log(len(Dict_docs)/int(Dict_df.get(t)))
  Q_A.append(tf_idf)
  

print(Q_A)

import re
Dict_map={}
file = open("sample_data/index.html", 'r')
text = file.read().strip()
file.close()
file_name = re.findall('><A HREF="(.*)">', text)
file_title = re.findall('<BR><TD> (.*)\n', text)
file_name.pop(0)
file_name.pop(0)

i=0
for item in file_name:
  Dict_map.update({item:file_title[i]})
  i=i+1
print(Dict_map)

import numpy as np
Q_A=np.array(Q_A)
print(Q_A)
mod_q=0
for item in Q_A:
  mod_q=mod_q+ item**2

mod_q=math.sqrt(mod_q)
print(mod_q)

######Cosine Similarity######
import numpy as np
from num2words import num2words
Dict_sim={}
Q_A_new=[]
for item in Q_A:
  Q_A_new.append(item/mod_q)

for doc in Dict_docs:
  Temp=[]
  D_A=[]

  title=Dict_map.get(doc)
  title_words=tokenizer.tokenize(title)
  TW=[]
  for w in title_words:
    if w.isdigit():
      TW.append(ps.stem(num2words(w))) 
    else:
      TW.append(ps.stem(w))  
    
  

  text = open(doc,"r+",errors='ignore') 
  var=(text.read())
  var=var.replace(',','')

  words=tokenizer.tokenize(var)
  
  for w in words:
    if w.isdigit():
      Temp.append(ps.stem(num2words(w)))
    else:

      Temp.append(ps.stem(w))  
  tf_idf=0
  for q_t in query_stem:
    count=0
    if q_t in Temp:
      
      for term in Temp:
        if q_t ==term:
          count=count+1
    #tf=1+math.log(1+count)
    tf=count

    if q_t not in stop_words and q_t in TW: 
      tf_idf=0.7*( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) )

    if q_t not in TW: 
      tf_idf=0.3*( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) )
    



   # tf_idf=( tf*math.log(len(Dict_docs)/int(Dict_df.get(q_t))) )
    D_A.append(tf_idf)
  D_A=np.array(D_A)
  mod_d=0
  D_A_new=[]
  for item in D_A:
    mod_d=mod_d+ item**2

  mod_d=math.sqrt(mod_d)
  
  for item in D_A:
    D_A_new.append(item/mod_d)

  similarity=0
  for i in range(0,len(D_A)):
    similarity=similarity+ (D_A[i]*Q_A[i])

  similarity=similarity
  Dict_sim.update({doc:similarity})
  #print(doc)
  #print(D_A)
  #print(mod_d)
  #print(mod_q)


import operator
Dict_sim= dict( sorted(Dict_sim.items(), key=operator.itemgetter(1),reverse=True)  ) 

print(Dict_sim)

k=20
for item in Dict_sim:
  print(item)
  k=k-1
  if k<=0:
    break